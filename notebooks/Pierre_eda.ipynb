{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Channel evolution analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import pyarrow.feather as feather\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.append(parent_dir)\n",
    "\n",
    "from utils.ploting import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NOTEBOOK_PATH = os.getcwd()\n",
    "MAIN_PATH = os.path.dirname(NOTEBOOK_PATH)\n",
    "DATA_PATH = os.path.join(MAIN_PATH, 'data_youniverse')\n",
    "SITE_DATA_PATH = os.path.join(MAIN_PATH, 'website_data')\n",
    "PEOPLE_AND_BLOGS_PATH = os.path.join(SITE_DATA_PATH, 'People_&_Blogs')\n",
    "\n",
    "if not os.path.exists(PEOPLE_AND_BLOGS_PATH):\n",
    "    os.makedirs(PEOPLE_AND_BLOGS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category_cc</th>\n",
       "      <th>join_date</th>\n",
       "      <th>channel</th>\n",
       "      <th>name_cc</th>\n",
       "      <th>subscribers_cc</th>\n",
       "      <th>videos_cc</th>\n",
       "      <th>subscriber_rank_sb</th>\n",
       "      <th>weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>People &amp; Blogs</td>\n",
       "      <td>2013-09-19</td>\n",
       "      <td>UCcgVECVN4OKV6DH1jLkqmcA</td>\n",
       "      <td>Jake Paul</td>\n",
       "      <td>19600000</td>\n",
       "      <td>824</td>\n",
       "      <td>144.0</td>\n",
       "      <td>2.0870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>People &amp; Blogs</td>\n",
       "      <td>2011-08-10</td>\n",
       "      <td>UCpko_-a4wgz2u_DgDgd9fqA</td>\n",
       "      <td>BuzzFeedVideo</td>\n",
       "      <td>19400000</td>\n",
       "      <td>6334</td>\n",
       "      <td>158.0</td>\n",
       "      <td>2.0870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>People &amp; Blogs</td>\n",
       "      <td>2016-01-10</td>\n",
       "      <td>UCWwWOFsW68TqXE-HZLC3WIA</td>\n",
       "      <td>The ACE Family</td>\n",
       "      <td>17600000</td>\n",
       "      <td>460</td>\n",
       "      <td>185.0</td>\n",
       "      <td>2.0870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>People &amp; Blogs</td>\n",
       "      <td>2006-12-06</td>\n",
       "      <td>UCAuUUnT6oDeKwE6v1NGQxug</td>\n",
       "      <td>TED</td>\n",
       "      <td>14800000</td>\n",
       "      <td>3105</td>\n",
       "      <td>211.0</td>\n",
       "      <td>2.0870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>People &amp; Blogs</td>\n",
       "      <td>2008-05-15</td>\n",
       "      <td>UCNL1ZadSjHpjm4q9j2sVtOA</td>\n",
       "      <td>Lady Gaga</td>\n",
       "      <td>14495273</td>\n",
       "      <td>163</td>\n",
       "      <td>238.0</td>\n",
       "      <td>2.0870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136442</th>\n",
       "      <td>People &amp; Blogs</td>\n",
       "      <td>2018-07-11</td>\n",
       "      <td>UC9mdbZJBLOWQkHIpoaJPjeQ</td>\n",
       "      <td>_Nevaeh Crockett_</td>\n",
       "      <td>10100</td>\n",
       "      <td>54</td>\n",
       "      <td>996760.0</td>\n",
       "      <td>53.1435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136461</th>\n",
       "      <td>People &amp; Blogs</td>\n",
       "      <td>2016-12-27</td>\n",
       "      <td>UCUe7JH_tgicQsaL2grkqrrQ</td>\n",
       "      <td>Multi-Fandom Girl</td>\n",
       "      <td>10000</td>\n",
       "      <td>12</td>\n",
       "      <td>1006793.0</td>\n",
       "      <td>53.1435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136462</th>\n",
       "      <td>People &amp; Blogs</td>\n",
       "      <td>2014-06-25</td>\n",
       "      <td>UC8jUn5SLi5dwjE5v6wY0UOg</td>\n",
       "      <td>Anastasiya Balan</td>\n",
       "      <td>10000</td>\n",
       "      <td>12</td>\n",
       "      <td>1007083.0</td>\n",
       "      <td>53.1435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136466</th>\n",
       "      <td>People &amp; Blogs</td>\n",
       "      <td>2013-10-17</td>\n",
       "      <td>UCtW9jp5TH0YrgYpwiRf9t-Q</td>\n",
       "      <td>saidthestory</td>\n",
       "      <td>10100</td>\n",
       "      <td>352</td>\n",
       "      <td>1008644.0</td>\n",
       "      <td>53.1435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136469</th>\n",
       "      <td>People &amp; Blogs</td>\n",
       "      <td>2006-11-11</td>\n",
       "      <td>UCITKvry4fW50iU4FSw9WERQ</td>\n",
       "      <td>Tangleblog</td>\n",
       "      <td>10000</td>\n",
       "      <td>159</td>\n",
       "      <td>1030844.0</td>\n",
       "      <td>53.1435</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18413 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           category_cc   join_date                   channel  \\\n",
       "89      People & Blogs  2013-09-19  UCcgVECVN4OKV6DH1jLkqmcA   \n",
       "98      People & Blogs  2011-08-10  UCpko_-a4wgz2u_DgDgd9fqA   \n",
       "120     People & Blogs  2016-01-10  UCWwWOFsW68TqXE-HZLC3WIA   \n",
       "137     People & Blogs  2006-12-06  UCAuUUnT6oDeKwE6v1NGQxug   \n",
       "154     People & Blogs  2008-05-15  UCNL1ZadSjHpjm4q9j2sVtOA   \n",
       "...                ...         ...                       ...   \n",
       "136442  People & Blogs  2018-07-11  UC9mdbZJBLOWQkHIpoaJPjeQ   \n",
       "136461  People & Blogs  2016-12-27  UCUe7JH_tgicQsaL2grkqrrQ   \n",
       "136462  People & Blogs  2014-06-25  UC8jUn5SLi5dwjE5v6wY0UOg   \n",
       "136466  People & Blogs  2013-10-17  UCtW9jp5TH0YrgYpwiRf9t-Q   \n",
       "136469  People & Blogs  2006-11-11  UCITKvry4fW50iU4FSw9WERQ   \n",
       "\n",
       "                  name_cc  subscribers_cc  videos_cc  subscriber_rank_sb  \\\n",
       "89              Jake Paul        19600000        824               144.0   \n",
       "98          BuzzFeedVideo        19400000       6334               158.0   \n",
       "120        The ACE Family        17600000        460               185.0   \n",
       "137                   TED        14800000       3105               211.0   \n",
       "154             Lady Gaga        14495273        163               238.0   \n",
       "...                   ...             ...        ...                 ...   \n",
       "136442  _Nevaeh Crockett_           10100         54            996760.0   \n",
       "136461  Multi-Fandom Girl           10000         12           1006793.0   \n",
       "136462   Anastasiya Balan           10000         12           1007083.0   \n",
       "136466       saidthestory           10100        352           1008644.0   \n",
       "136469         Tangleblog           10000        159           1030844.0   \n",
       "\n",
       "        weights  \n",
       "89       2.0870  \n",
       "98       2.0870  \n",
       "120      2.0870  \n",
       "137      2.0870  \n",
       "154      2.0870  \n",
       "...         ...  \n",
       "136442  53.1435  \n",
       "136461  53.1435  \n",
       "136462  53.1435  \n",
       "136466  53.1435  \n",
       "136469  53.1435  \n",
       "\n",
       "[18413 rows x 8 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(os.path.join(PEOPLE_AND_BLOGS_PATH, 'df_PB_channels.csv'), compression='infer', index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>index</th>\n",
       "      <th>categories</th>\n",
       "      <th>channel_id</th>\n",
       "      <th>dislike_count</th>\n",
       "      <th>display_id</th>\n",
       "      <th>duration</th>\n",
       "      <th>like_count</th>\n",
       "      <th>upload_date</th>\n",
       "      <th>view_count</th>\n",
       "      <th>year_month</th>\n",
       "      <th>like_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1783</td>\n",
       "      <td>People &amp; Blogs</td>\n",
       "      <td>UCzWmWTPCafQRNl9q9Y53AfQ</td>\n",
       "      <td>613.0</td>\n",
       "      <td>BDnF-EgqAGw</td>\n",
       "      <td>398</td>\n",
       "      <td>49464.0</td>\n",
       "      <td>2019-02-05</td>\n",
       "      <td>1142835.0</td>\n",
       "      <td>2019-02</td>\n",
       "      <td>0.987759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1784</td>\n",
       "      <td>People &amp; Blogs</td>\n",
       "      <td>UCzWmWTPCafQRNl9q9Y53AfQ</td>\n",
       "      <td>588.0</td>\n",
       "      <td>wrTIXbQED80</td>\n",
       "      <td>375</td>\n",
       "      <td>32726.0</td>\n",
       "      <td>2019-01-31</td>\n",
       "      <td>819654.0</td>\n",
       "      <td>2019-01</td>\n",
       "      <td>0.982350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1785</td>\n",
       "      <td>People &amp; Blogs</td>\n",
       "      <td>UCzWmWTPCafQRNl9q9Y53AfQ</td>\n",
       "      <td>1177.0</td>\n",
       "      <td>uyWL0ZWibyU</td>\n",
       "      <td>335</td>\n",
       "      <td>86222.0</td>\n",
       "      <td>2019-01-22</td>\n",
       "      <td>2159837.0</td>\n",
       "      <td>2019-01</td>\n",
       "      <td>0.986533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1786</td>\n",
       "      <td>People &amp; Blogs</td>\n",
       "      <td>UCzWmWTPCafQRNl9q9Y53AfQ</td>\n",
       "      <td>673.0</td>\n",
       "      <td>yd7d51AgSso</td>\n",
       "      <td>319</td>\n",
       "      <td>30596.0</td>\n",
       "      <td>2019-01-15</td>\n",
       "      <td>736707.0</td>\n",
       "      <td>2019-01</td>\n",
       "      <td>0.978477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1787</td>\n",
       "      <td>People &amp; Blogs</td>\n",
       "      <td>UCzWmWTPCafQRNl9q9Y53AfQ</td>\n",
       "      <td>991.0</td>\n",
       "      <td>-Ia18bqO-9w</td>\n",
       "      <td>367</td>\n",
       "      <td>75504.0</td>\n",
       "      <td>2019-01-09</td>\n",
       "      <td>1636316.0</td>\n",
       "      <td>2019-01</td>\n",
       "      <td>0.987045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5553832</th>\n",
       "      <td>5553832</td>\n",
       "      <td>72904887</td>\n",
       "      <td>People &amp; Blogs</td>\n",
       "      <td>UCrwRLYg4dbkrxDbbnaQd48g</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Z3mXSYy3qBk</td>\n",
       "      <td>165</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2016-03-31</td>\n",
       "      <td>426.0</td>\n",
       "      <td>2016-03</td>\n",
       "      <td>0.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5553833</th>\n",
       "      <td>5553833</td>\n",
       "      <td>72904888</td>\n",
       "      <td>People &amp; Blogs</td>\n",
       "      <td>UCrwRLYg4dbkrxDbbnaQd48g</td>\n",
       "      <td>0.0</td>\n",
       "      <td>fiHAotJWQ1k</td>\n",
       "      <td>148</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2016-03-31</td>\n",
       "      <td>659.0</td>\n",
       "      <td>2016-03</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5553834</th>\n",
       "      <td>5553834</td>\n",
       "      <td>72904889</td>\n",
       "      <td>People &amp; Blogs</td>\n",
       "      <td>UCrwRLYg4dbkrxDbbnaQd48g</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-sVZEtcIB0I</td>\n",
       "      <td>188</td>\n",
       "      <td>32.0</td>\n",
       "      <td>2016-03-31</td>\n",
       "      <td>863.0</td>\n",
       "      <td>2016-03</td>\n",
       "      <td>0.969697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5553835</th>\n",
       "      <td>5553835</td>\n",
       "      <td>72904890</td>\n",
       "      <td>People &amp; Blogs</td>\n",
       "      <td>UCrwRLYg4dbkrxDbbnaQd48g</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Wi4dcBmmzK8</td>\n",
       "      <td>144</td>\n",
       "      <td>137.0</td>\n",
       "      <td>2016-03-18</td>\n",
       "      <td>2528.0</td>\n",
       "      <td>2016-03</td>\n",
       "      <td>0.992754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5553836</th>\n",
       "      <td>5553836</td>\n",
       "      <td>72904891</td>\n",
       "      <td>People &amp; Blogs</td>\n",
       "      <td>UCrwRLYg4dbkrxDbbnaQd48g</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3osx3gHXrh0</td>\n",
       "      <td>224</td>\n",
       "      <td>80.0</td>\n",
       "      <td>2016-03-16</td>\n",
       "      <td>2482.0</td>\n",
       "      <td>2016-03</td>\n",
       "      <td>0.963855</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5553837 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         level_0     index      categories                channel_id  \\\n",
       "0              0      1783  People & Blogs  UCzWmWTPCafQRNl9q9Y53AfQ   \n",
       "1              1      1784  People & Blogs  UCzWmWTPCafQRNl9q9Y53AfQ   \n",
       "2              2      1785  People & Blogs  UCzWmWTPCafQRNl9q9Y53AfQ   \n",
       "3              3      1786  People & Blogs  UCzWmWTPCafQRNl9q9Y53AfQ   \n",
       "4              4      1787  People & Blogs  UCzWmWTPCafQRNl9q9Y53AfQ   \n",
       "...          ...       ...             ...                       ...   \n",
       "5553832  5553832  72904887  People & Blogs  UCrwRLYg4dbkrxDbbnaQd48g   \n",
       "5553833  5553833  72904888  People & Blogs  UCrwRLYg4dbkrxDbbnaQd48g   \n",
       "5553834  5553834  72904889  People & Blogs  UCrwRLYg4dbkrxDbbnaQd48g   \n",
       "5553835  5553835  72904890  People & Blogs  UCrwRLYg4dbkrxDbbnaQd48g   \n",
       "5553836  5553836  72904891  People & Blogs  UCrwRLYg4dbkrxDbbnaQd48g   \n",
       "\n",
       "         dislike_count   display_id  duration  like_count upload_date  \\\n",
       "0                613.0  BDnF-EgqAGw       398     49464.0  2019-02-05   \n",
       "1                588.0  wrTIXbQED80       375     32726.0  2019-01-31   \n",
       "2               1177.0  uyWL0ZWibyU       335     86222.0  2019-01-22   \n",
       "3                673.0  yd7d51AgSso       319     30596.0  2019-01-15   \n",
       "4                991.0  -Ia18bqO-9w       367     75504.0  2019-01-09   \n",
       "...                ...          ...       ...         ...         ...   \n",
       "5553832            1.0  Z3mXSYy3qBk       165        19.0  2016-03-31   \n",
       "5553833            0.0  fiHAotJWQ1k       148        29.0  2016-03-31   \n",
       "5553834            1.0  -sVZEtcIB0I       188        32.0  2016-03-31   \n",
       "5553835            1.0  Wi4dcBmmzK8       144       137.0  2016-03-18   \n",
       "5553836            3.0  3osx3gHXrh0       224        80.0  2016-03-16   \n",
       "\n",
       "         view_count year_month  like_rate  \n",
       "0         1142835.0    2019-02   0.987759  \n",
       "1          819654.0    2019-01   0.982350  \n",
       "2         2159837.0    2019-01   0.986533  \n",
       "3          736707.0    2019-01   0.978477  \n",
       "4         1636316.0    2019-01   0.987045  \n",
       "...             ...        ...        ...  \n",
       "5553832       426.0    2016-03   0.950000  \n",
       "5553833       659.0    2016-03   1.000000  \n",
       "5553834       863.0    2016-03   0.969697  \n",
       "5553835      2528.0    2016-03   0.992754  \n",
       "5553836      2482.0    2016-03   0.963855  \n",
       "\n",
       "[5553837 rows x 12 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(os.path.join(PEOPLE_AND_BLOGS_PATH, 'df_PB_helper.csv.gz'), compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feather = feather.read_feather(os.path.join(DATA_PATH, 'yt_metadata_helper.feather')) # 9m : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = pd.read_csv(os.path.join(DATA_PATH, \"df_channels_en.tsv.gz\"), compression=\"infer\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries = pd.read_csv(f\"{DATA_PATH}/df_timeseries_en.tsv.gz\", compression=\"infer\", sep=\"\\t\") # 20s\n",
    "timeseries.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels[\"join_date\"] = pd.to_datetime(channels[\"join_date\"])\n",
    "timeseries[\"datetime\"] = pd.to_datetime(timeseries[\"datetime\"])\n",
    "df_feather[\"upload_date\"] = pd.to_datetime(df_feather[\"upload_date\"])\n",
    "df_feather[\"year_month\"] = df_feather['upload_date'].dt.to_period('M')\n",
    "df_feather[\"like_rate\"] = df_feather[\"like_count\"] / (df_feather[\"like_count\"] + df_feather[\"dislike_count\"])\n",
    "channels_PB = channels[channels['category_cc'] == \"People & Blogs\"]\n",
    "df_feather_PB = df_feather[df_feather[\"channel_id\"].isin(channels_PB[\"channel\"])]\n",
    "timeseries_PB = timeseries[timeseries['channel'].isin(channels_PB['channel'])]\n",
    "df_feather.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import string\n",
    "\n",
    "# # Assuming df_channels is your dataframe and 'name_cc' is the column with channel names\n",
    "# # Create a temporary column 'name_cc_sorted' that has punctuation removed\n",
    "# channels_PB['name_cc_sorted'] = channels_PB['name_cc'].str.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "# # Sort the dataframe using the new column\n",
    "# channels_PB.sort_values(by='name_cc_sorted', inplace=True)\n",
    "\n",
    "# # Drop the temporary sorting column\n",
    "# channels_PB.drop(columns=['name_cc_sorted'], inplace=True)\n",
    "\n",
    "# channels_PB.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feather_PB.reset_index().to_csv(os.path.join(PEOPLE_AND_BLOGS_PATH, 'df_PB_helper.csv.gz'), compression='gzip', index=False)\n",
    "channels_PB.to_csv(os.path.join(PEOPLE_AND_BLOGS_PATH,\"df_PB_channels.csv.gz\"), compression=\"gzip\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels_PB.sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_not_diverse_channels(channel_id, df_feather=df_feather_PB, show_evolution=False):\n",
    "    '''\n",
    "    Calculates the proportion of videos in the 'People & Blogs' category for a given channel.\n",
    "\n",
    "    Parameters:\n",
    "    - channel_id (str): The YouTube channel ID.\n",
    "    - df_feather (DataFrame): DataFrame containing video data.\n",
    "\n",
    "    Returns:\n",
    "    - bool: True if the proportion of 'People & Blogs' videos is less than 75%, False otherwise.\n",
    "    '''\n",
    "    df_filtered = df_feather[df_feather[\"channel_id\"] == channel_id]\n",
    "    grouped_data = df_filtered.groupby([\"year_month\", \"categories\"]).size()\n",
    "    # display(grouped_data)\n",
    "    sorted_data = grouped_data.reset_index(name='count').sort_values(['year_month', 'count'], ascending=[True, False])\n",
    "    if show_evolution:\n",
    "        display(sorted_data)\n",
    "\n",
    "    most_popular_cat = sorted_data.drop_duplicates(subset=[\"year_month\"])\n",
    "    # display(most_popular_cat)\n",
    "\n",
    "    people_and_blog_proportion = (most_popular_cat[\"categories\"] == \"People & Blogs\").mean()\n",
    "    # print(people_and_blog_proportion)\n",
    "    return people_and_blog_proportion < 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 100\n",
    "channels_PB_transi_mask = channels_PB[:i].progress_apply(lambda channel: filter_not_diverse_channels(channel[\"channel\"]), axis=1)\n",
    "channels_PB_transi = channels_PB[:i][channels_PB_transi_mask]\n",
    "print(f\"There are {len(channels_PB[:i])} channels in PB category, but only {len(channels_PB_transi)} have less than 0.75 video in that category\")\n",
    "# channels_PB_transi.sample(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for channel_id in channels_PB_transi['channel'].unique()[:5]:\n",
    "    visualize_evolution_of_channel(channel_id, df_feather_PB, channels_PB)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_ids = ['UC4-CH0epzZpD_ARhxCx6LaQ', 'UCYd0us2OtW4d4-1cfpT2ktw']\n",
    "# for channel_id in channel_ids:\n",
    "#     visualize_evolution_of_channel(channel_id, df_feather_PB, channels_PB)\n",
    "\n",
    "visualize_evolution_of_channel(channel_ids[0], df_feather_PB, channels_PB, start_date=\"2016-09\", end_date=\"2019-09\", transition_date=\"2018-02\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_ids = ['UC4-CH0epzZpD_ARhxCx6LaQ', 'UC0oRdyzTbGIZUISiGQnDdiw']\n",
    "video_frequency_and_duration(channel_ids, df_feather, channels, start_date=\"2016-09\", end_date=\"2019-09\", transition_date=\"2018-03\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_ids = ['UC4-CH0epzZpD_ARhxCx6LaQ', 'UC0oRdyzTbGIZUISiGQnDdiw']\n",
    "video_likes_and_views(channel_ids, df_feather, channels, start_date=\"2016-09\", end_date=\"2019-09\", transition_date=\"2018-03\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2nd milestone stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# import os \n",
    "# import pandas as pd\n",
    "# import seaborn as sns\n",
    "# import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def category_evolution_of_channel_v0(channel_id, channels=channels_PB, df_feather=df_feather_PB):\n",
    "#     '''\n",
    "#     Input : a channel id, channels information dataframe and video metadata via df_feather\n",
    "#     Output : annual count of number of videos of that channel in every category\n",
    "#     Note : df_feather['upload_date'] should be already in datetime format\n",
    "#     '''\n",
    "#     # get info on the channel\n",
    "#     # channel_info = channels[channels[\"channel\"] == channel_id]\n",
    "#     # display(channel_info)\n",
    "\n",
    "#     df_feather_filt = df_feather[df_feather[\"channel_id\"] == channel_id]\n",
    "#     # For every year, count videos in each category\n",
    "#     grouped_data = df_feather_filt[[\"year_month\", \"categories\", \"channel_id\"]]\n",
    "#     grouped_data = grouped_data.groupby([\"year_month\", \"categories\"]).count()\n",
    "#     # Sort the values (need to transform in a regular dataframe and then put back indexes)\n",
    "#     sorted_data = grouped_data.reset_index().sort_values(['year_month', 'channel_id'], ascending=[True, False])\n",
    "#     sorted_data.set_index(['year_month', 'categories'], inplace=True)\n",
    "#     # display(sorted_data)\n",
    "\n",
    "#     # Select only the most popular category every year\n",
    "#     most_popular_cat = sorted_data.reset_index().drop_duplicates(subset=[\"year_month\"])\n",
    "#     # display(most_popular_cat)\n",
    "\n",
    "#     people_and_blog_proportion = len(most_popular_cat[most_popular_cat[\"categories\"]==\"People & Blogs\"]) / len(most_popular_cat)\n",
    "#     # print(people_and_blog_proportion)\n",
    "\n",
    "#     return people_and_blog_proportion < 0.75\n",
    "\n",
    "# # channel_id = 'UCcgVECVN4OKV6DH1jLkqmcA'\n",
    "# # category_evolution_of_channel(channel_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTEBOOK_PATH = os.getcwd()\n",
    "# DIR_PATH = os.path.dirname(NOTEBOOK_PATH)\n",
    "# DATA_PATH = os.path.join(DIR_PATH, \"data_youniverse\")\n",
    "# UTILS_PATH = os.path.join(DIR_PATH, \"utils\")\n",
    "# CATEGORY = \"Science & Technology\"\n",
    "\n",
    "# # append utils path and import utils\n",
    "# sys.path.append(UTILS_PATH)\n",
    "# from ploting import *\n",
    "# from loading import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_channels_en = pd.read_csv(f\"{DATA_PATH}/df_channels_en.tsv.gz\", compression=\"infer\", sep=\"\\t\") \n",
    "# # df_channels_en.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_timeseries_en = pd.read_csv(f\"{DATA_PATH}/df_timeseries_en.tsv.gz\", compression=\"infer\", sep=\"\\t\") # 20s\n",
    "# # df_timeseries_en.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_timeseries_en[df_timeseries_en['category'].isna()].channel.unique().size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_channels_filt = df_channels_en[df_channels_en['category_cc'] == CATEGORY].copy()\n",
    "# df_timeseries_filt = df_timeseries_en[df_timeseries_en['category'] == CATEGORY].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper_filt = read_and_filter_feather(f\"{DATA_PATH}/yt_metadata_helper.feather\", CATEGORY)\n",
    "# helper_filt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # UNCOMMENT IF NEEDED\n",
    "# yt_metadata_filtered = load_and_filter_jsonl_gz_file_by_chunks(f\"{DATA_PATH}/yt_metadata_en.jsonl.gz\", CATEGORY) # 21m for pets and animals (should be the same for the other at it is reading all the file anyway)\n",
    "# yt_metadata_filtered.to_csv(f\"{DATA_PATH}/yt_metadata_pets&animals.csv.gz\", index=False, compression=\"gzip\") # stock the results\n",
    "# yt_metadata_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yt_metadata_filtered.iloc[-1]['tags']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of pets & animals category and tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yt_metadata_filt = pd.read_csv(f\"{DATA_PATH}/yt_metadata_pets&animals.csv.gz\", compression=\"infer\")\n",
    "# # les channels id sont les vrai, ont peut retrouver les chaines youtube !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yt_metadata_filt['upload_date'] = pd.to_datetime(yt_metadata_filt['upload_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yt_metadata_filt.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the top 3 tags for a range of years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# years = range(2016, 2020)  # or whatever years are applicable\n",
    "# for year in years:\n",
    "#     yt_metadata_filt_year = yt_metadata_filt[yt_metadata_filt['upload_date'].dt.year == year]\n",
    "#     if not yt_metadata_filt_year.empty:\n",
    "#         try:\n",
    "#             # Assuming the function plot_topN_tag is correctly defined and can handle cases with less than N tags\n",
    "#             plot_topN_tag(yt_metadata_filt_year['tags'], 3)\n",
    "#         except Exception as e:\n",
    "#             print(f\"An error occurred for year {year}: {e}\")\n",
    "#     else:\n",
    "#         print(f\"No data available for year {year}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning of NaN values (not extensive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def clean_dataframe(df):\n",
    "#     # Remove rows where 'tags' is empty or NaN\n",
    "#     initial_row_count = len(df)\n",
    "#     df = df.dropna(subset=['tags'])  # Drops rows with NaN in 'tags'\n",
    "#     df = df[df['tags'].str.strip().astype(bool)]  # Drops rows with empty 'tags'\n",
    "#     cleaned_row_count = len(df)\n",
    "\n",
    "#     # Check for NaN values in 'like_count'\n",
    "#     like_count_nan = df['like_count'].isna().sum()\n",
    "#     if like_count_nan > 0:\n",
    "#         # Handle NaN values here. Options: fill with 0, mean, median, etc.\n",
    "#         # Example: df['like_count'].fillna(df['like_count'].median(), inplace=True)\n",
    "#         # For now, we'll just drop these rows\n",
    "#         df = df.dropna(subset=['like_count'])\n",
    "\n",
    "#     # Print out the cleaning summary\n",
    "#     print(f\"Rows with empty 'tags' removed: {initial_row_count - cleaned_row_count}\")\n",
    "#     print(f\"Rows with NaN in 'like_count': {like_count_nan}\")\n",
    "\n",
    "#     return df\n",
    "\n",
    "# # Clean the yt_metadata_filtered dataframe\n",
    "# yt_metadata_filt_clean = clean_dataframe(yt_metadata_filt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot evolution of most popular tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_top_tags_for_year(df, year, top_n=5):\n",
    "#     \"\"\" Get the top N tags for a given year from the dataframe \"\"\"\n",
    "#     year_data = df[df['upload_date'].dt.year == year]\n",
    "#     tag_list = year_data['tags'].str.split(',').explode()\n",
    "#     top_tags = tag_list.value_counts().head(top_n).index\n",
    "#     return top_tags\n",
    "\n",
    "# def count_tag_appearances_by_year(df, tags):\n",
    "#     \"\"\" Count the number of appearances of each tag by year \"\"\"\n",
    "#     df['year'] = df['upload_date'].dt.year\n",
    "#     tag_counts_by_year = {tag: df[df['tags'].str.contains(tag)]['year'].value_counts().sort_index() for tag in tags}\n",
    "#     return tag_counts_by_year\n",
    "\n",
    "# def plot_tag_counts(tag_counts_by_year):\n",
    "#     \"\"\" Plot the evolution of tag counts over the years \"\"\"\n",
    "#     plt.figure(figsize=(10, 8))\n",
    "#     for tag, counts in tag_counts_by_year.items():\n",
    "#         plt.plot(counts.index, counts.values, label=tag)\n",
    "    \n",
    "#     plt.xlabel('Year')\n",
    "#     plt.ylabel('Number of Appearances')\n",
    "#     plt.title('Evolution of Tag Appearances by Year')\n",
    "#     plt.legend()\n",
    "#     plt.show()\n",
    "\n",
    "# top_tags_2019 = get_top_tags_for_year(yt_metadata_filt_clean, 2019)\n",
    "# tag_counts_by_year = count_tag_appearances_by_year(yt_metadata_filt_clean, top_tags_2019)\n",
    "# plot_tag_counts(tag_counts_by_year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframe of statistics grouped by year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convert `upload_date` to DateTime and extract the year.\n",
    "# yt_metadata_filt['upload_year'] = pd.to_datetime(yt_metadata_filt['upload_date']).dt.year\n",
    "\n",
    "# # Group by the extracted year.\n",
    "# grouped = yt_metadata_filt.groupby('upload_year')\n",
    "\n",
    "# # Initialize a dictionary to hold aggregated data.\n",
    "# aggregated_data = {}\n",
    "\n",
    "# # Iterate over each group to perform aggregations.\n",
    "# for name, group in grouped:\n",
    "#     # Get the most popular tag for each year.\n",
    "#     popular_tag = group['tags'].str.split(',').explode().value_counts().idxmax()\n",
    "    \n",
    "#     # Get other statistics for each year.\n",
    "#     aggregated_data[name] = {\n",
    "#         'most_popular_tag': popular_tag,\n",
    "#         'total_like_count': group['like_count'].sum(),\n",
    "#         'total_videos': group['upload_date'].count(),\n",
    "#         'total_duration': group['duration'].sum(),\n",
    "#         'unique_channels': group['channel_id'].nunique(),\n",
    "#         'total_dislike_count': group['dislike_count'].sum(),\n",
    "#         'total_view_count': group['view_count'].sum(),\n",
    "#         'mean_dislike_count': group['dislike_count'].mean(),\n",
    "#         'mean_like_count': group['like_count'].mean(),\n",
    "#         'mean_duration': group['duration'].mean(),\n",
    "#     }\n",
    "\n",
    "# # Convert aggregated data to a DataFrame.\n",
    "# stats_df = pd.DataFrame.from_dict(aggregated_data, orient='index')\n",
    "\n",
    "# # Display the DataFrame\n",
    "# stats_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot evolution of metrics of previous dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_stats_over_years(df, columns):\n",
    "#     \"\"\"\n",
    "#     Plots the evolution of specified columns from a DataFrame over the years.\n",
    "    \n",
    "#     Parameters:\n",
    "#     - df: pandas DataFrame with a year index and columns to plot.\n",
    "#     - columns: list of strings representing the column names to plot.\n",
    "#     \"\"\"\n",
    "#     if not isinstance(columns, list):\n",
    "#         columns = [columns]  # Convert to list if a single column name is passed.\n",
    "        \n",
    "#     for column in columns:\n",
    "#         if column in df.columns:\n",
    "#             plt.plot(df.index, df[column], label=column)\n",
    "#         else:\n",
    "#             print(f\"Column '{column}' not found in the DataFrame.\")\n",
    "    \n",
    "#     plt.xlabel('Year')\n",
    "#     plt.ylabel('Value')\n",
    "#     plt.title('Evolution of Statistics Over Years')\n",
    "#     plt.legend()\n",
    "#     plt.show()\n",
    "\n",
    "# plot_stats_over_years(stats_df, ['total_like_count', 'total_dislike_count'])\n",
    "# plot_stats_over_years(stats_df, ['mean_dislike_count', 'mean_like_count', 'mean_duration'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ada",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
